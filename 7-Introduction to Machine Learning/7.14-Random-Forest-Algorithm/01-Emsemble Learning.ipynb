{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5a20020",
   "metadata": {},
   "source": [
    "# What is Ensemble Learning?\n",
    "\n",
    "**Ensemble Learning** is a machine learning technique where we combine **multiple models** (called weak learners) **to build a stronger and more accurate model**.\n",
    "\n",
    "### Think of it like:\n",
    "**“Many models vote together to make a better decision.”**\n",
    "\n",
    "---\n",
    "\n",
    "### Why Use Ensemble Learning?\n",
    "\n",
    "Ensemble methods help to:\n",
    "\n",
    "✔️ Increase accuracy\n",
    "\n",
    "✔️ Reduce variance\n",
    "\n",
    "✔️ Reduce overfitting\n",
    "\n",
    "✔️ Improve stability\n",
    "\n",
    "✔️ Perform better than individual models\n",
    "\n",
    "---\n",
    "\n",
    "## Why Does It Work?\n",
    "\n",
    "Because each model may make different mistakes.\n",
    "When you combine them:\n",
    "\n",
    "- Errors cancel out\n",
    "\n",
    "- Strengths reinforce each other\n",
    "\n",
    "- Final prediction becomes more robust\n",
    "\n",
    "---\n",
    "\n",
    "## Types of Ensemble Learning\n",
    "\n",
    "There are three major types:\n",
    "\n",
    "### 1️⃣ **Bagging (Bootstrap Aggregating)**\n",
    "\n",
    "- Train **multiple models independently**.\n",
    "\n",
    "- Each model gets a **random subset of data** (with replacement).\n",
    "\n",
    "- **Final prediction → Majority vote (classification) or average (regression)**\n",
    "\n",
    "**Famous Algorithm:**\n",
    "\n",
    "✔️ *Random Forest*\n",
    "\n",
    "**Key Benefit:**\n",
    "\n",
    "✔️ *Reduces variance*\n",
    "\n",
    "\n",
    "### 2️⃣ **Boosting**\n",
    "\n",
    "- Models are trained **sequentially**.\n",
    "\n",
    "- Each new model focuses on **fixing the mistakes** of the **previous one**.\n",
    "\n",
    "- Final prediction → weighted vote or sum\n",
    "\n",
    "**Famous Algorithms:**\n",
    "\n",
    "✔️ *AdaBoost*.\n",
    "\n",
    "✔️ *Gradient Boosting*.\n",
    "\n",
    "✔️ *XGBoost*.\n",
    "\n",
    "✔️ *LightGBM*.\n",
    "\n",
    "✔️ *CatBoost*.\n",
    "\n",
    "**Key Benefit:**\n",
    "\n",
    "✔️ *Reduces bias*\n",
    "\n",
    "### 3️⃣ **Stacking (Stacked Generalization)**\n",
    "\n",
    "- Train different types of models.\n",
    "\n",
    "- Their predictions are combined by a meta-model (usually a linear model or another tree).\n",
    "\n",
    "        Model 1 → Logistic Regression\n",
    "        Model 2 → Decision Tree\n",
    "        Model 3 → SVM\n",
    "        Meta Model → Random Forest\n",
    "\n",
    "**Key Benefit:**\n",
    "\n",
    "✔️ Learns better combinations of predictions\n",
    "\n",
    "---\n",
    "\n",
    "## How Ensembles Improve Performance\n",
    "\n",
    "| Issue            | Ensemble Solution                 |\n",
    "| ---------------- | --------------------------------- |\n",
    "| High variance    | Bagging stabilizes predictions    |\n",
    "| High bias        | Boosting improves weak models     |\n",
    "| Complex patterns | Stacking combines model strengths |\n",
    "\n",
    "--- \n",
    "\n",
    "## Real-World Examples\n",
    "\n",
    "- **Random Forest** → Used everywhere (finance, healthcare, e-commerce)\n",
    "\n",
    "- **XGBoost** → Winning ML competitions (Kaggle)\n",
    "\n",
    "- **AdaBoost** → Face detection\n",
    "\n",
    "- **LightGBM**→ Real-time prediction systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137ec2c4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Ensemble Learning is the process of combining multiple models to improve accuracy,\n",
    "reduce variance, and produce more stable predictions.\n",
    "\n",
    "Types:\n",
    "1. Bagging → trains models independently on random samples (Random Forest)\n",
    "2. Boosting → trains models sequentially where each new model corrects previous errors (XGBoost, AdaBoost)\n",
    "3. Stacking → combines different models using a meta-learner\n",
    "\n",
    "Ensembles work because multiple weak learners create a strong learner.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
